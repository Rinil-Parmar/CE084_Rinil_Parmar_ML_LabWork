{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQ6iRsdnkSBzfOVh6g0oSV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Doubts : \n","\n","1.   What is the use of DataLoader?\n","2.   \n","\n"],"metadata":{"id":"4ABBdiChSr5t"}},{"cell_type":"markdown","source":["# Outline : \n","\n","\n","\n","*   Load mnist dataset (done)\n","*   flatten 2d image to 1d array (done)\n","*   Normalize images value from [0, 255] to [0, 1] (done)\n","*   create feature and targets tensor for train and test set.(done)\n","*   define epoch (done)\n","*   data loader \n","*   visualize one of the images in data set \n","*   \n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"3ZDeN523MIXz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":752},"id":"cM0J-GizLzCo","executionInfo":{"status":"error","timestamp":1678786619820,"user_tz":-330,"elapsed":624,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"7a4b5233-de76-4018-ee94-d6141c6aea20"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["tensor(5, dtype=torch.uint8)\n","num_epochs :  5000\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-51ce88fe68c8>:62: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  trainset=np.array(list(zip(X_train,y_train)))\n","<ipython-input-40-51ce88fe68c8>:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  trainset=np.array(list(zip(X_train,y_train)))\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-51ce88fe68c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Convert the inputs and labels to Variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# array of string classes and object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp_str_obj_array_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import mnist\n","from sklearn.preprocessing import MinMaxScaler\n","from random import random\n","\n","def flatten(X_data):\n","  flatten_data=[]\n","  for i in range(len(X_data)):\n","    sample=X_data[i]\n","    flatten_row=[]\n","    for row in sample:\n","      flatten_row+=list(row)\n","      pass\n","    pass\n","    flatten_data.append(np.array(flatten_row,dtype='float32'))\n","    pass\n","  return np.array(flatten_data)\n","  pass\n","\n","\n","(X_train, y_train), (X_test,y_test) = mnist.load_data()\n","\n","X_train=X_train[0:100]\n","y_train=y_train[0:100]\n","\n","# visualize one of the images in data set\n","sample_image_mat=X_train[int(random()*len(X_train))]\n","plt.imshow(sample_image_mat)\n","plt.show()\n","\n","\n","X_train=flatten(X_train)\n","# X_test=flatten(X_test)\n","\n","scaler = MinMaxScaler().fit(X_train)\n","X_train=scaler.transform(X_train)\n","# X_test=scaler.transform(X_test)\n","\n","X_train=torch.tensor(X_train)\n","# X_test=torch.tensor(X_test)\n","\n","y_train=torch.tensor(y_train)\n","# y_test=torch.tensor(y_test)\n","\n","print(y_train[0])\n","\n","batch_size = 100\n","n_iters = 5000\n","\n","num_epochs = n_iters / (len(X_train) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","print(\"num_epochs : \",num_epochs)\n","trainset=np.array(list(zip(X_train,y_train)))\n","trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True)\n","\n","\n","# dataiter = iter(trainloader)\n","# for _ in range(len(X_train)-1):\n","#   input,target=next(dataiter)\n","#   print(target,input)\n","#   pass\n","# print(trainloader)\n","\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import TensorDataset,DataLoader\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import mnist\n","import tensorflow as tf\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score\n","from random import random\n","\n","def flatten(X_data):\n","    flatten_data=[]\n","    for i in range(len(X_data)):\n","        sample=X_data[i]\n","        flatten_row=[]\n","        for row in sample:\n","            flatten_row+=list(row)\n","        flatten_data.append(np.array(flatten_row,dtype='float32'))\n","    return np.array(flatten_data)\n","\n","class ANNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n","        super(ANNModel, self).__init__()\n","        self.sigmoid = nn.Sigmoid()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n","        self.fc2 = nn.Linear(hidden_dim1, output_dim)\n","        # self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n","        # self.fc3 = nn.Linear(hidden_dim2, output_dim)\n","        \n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.sigmoid(out)\n","        out = self.fc2(out)\n","        out = self.sigmoid(out)\n","        # out = self.fc3(out)\n","        # out = self.sigmoid(out)\n","        \n","        return out\n","\n","    def predict(self,x):\n","        \n","        output=self.forward(x).tolist()\n","        output_labels=[]\n","        for elem in output : \n","          lbl=elem.index(max(elem))\n","          output_labels.append(lbl)\n","        # print(output_labels)\n","        output_labels=np.array(output_labels)\n","        # print(\"label : \",lbl)\n","        # print(output)\n","        return output_labels\n","        pass\n","\n","(X_train, y_train), (X_test,y_test) = mnist.load_data()\n","\n","X_train=X_train[0:100]\n","X_test=X_test[0:100]\n","y_train=y_train[0:100]\n","y_test=y_test[0:100]\n","\n","# visualize one of the images in data set\n","sample_image_mat=X_train[int(random()*len(X_train))]\n","plt.imshow(sample_image_mat)\n","plt.show()\n","\n","X_train=flatten(X_train)\n","X_test=flatten(X_test)\n","\n","scaler = MinMaxScaler().fit(X_train)\n","X_train=scaler.transform(X_train)\n","\n","X_train=torch.tensor(X_train)\n","X_test=torch.tensor(X_test)\n","y_train=torch.tensor(y_train)\n","y_test=torch.tensor(y_test)\n","\n","print(y_train[0])\n","\n","batch_size = 10\n","n_iters = 10000\n","\n","num_epochs = n_iters / (len(X_train) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","print(\"num_epochs : \",num_epochs)\n","# trainset = [(X_train[i], y_train[i]) for i in range(len(X_train))]\n","trainset=TensorDataset(X_train,y_train)\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","# dataiter = iter(trainloader)\n","\n","# while True:\n","#   try:\n","#     input, target = next(dataiter)\n","#     print(target)\n","#   except StopIteration:\n","#     break\n","\n","input_dim = X_train.shape[1]\n","hidden_dim1 = 50\n","hidden_dim2 = 100\n","output_dim = 10\n","\n","model = ANNModel(input_dim, hidden_dim1,hidden_dim2, output_dim)\n","\n","# criterion = nn.CrossEntropyLoss()\n","# criterion=tf.keras.losses.CategoricalCrossentropy()\n","criterion=nn.MSELoss()\n","\n","learning_rate = 0.1\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","\n","for epoch in range(num_epochs):\n","  for i, (images, labels) in enumerate(trainloader):\n","    inputs = Variable(images.view(-1, input_dim))\n","    labels = Variable(labels)\n","    optimizer.zero_grad()\n","    outputs=model(inputs)\n","    # outputs = torch.tensor(model(inputs),dtype=torch.float)\n","    # labels = torch.tensor(labels,dtype=torch.float)\n","    # print(outputs.shape,labels.shape)\n","    # print(outputs,labels)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    # if (i+1) % 10 == 0:\n","    #     print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n","    #           % (epoch+1, num_epochs, i+1, len(trainset)//batch_size, loss.item()))\n","    pass\n","  pass\n","\n","\n","# print(model.forward())\n","sample=torch.tensor(flatten([sample_image_mat]))\n","print(model.predict(sample))\n","y_pred=torch.tensor(model.predict(X_test))\n","# print(y_pred,y_test)\n","print(accuracy_score(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"DkoCm6FdbqoP","executionInfo":{"status":"error","timestamp":1679835774233,"user_tz":-330,"elapsed":977,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"b2c56149-8659-4355-ac6c-d43452936ede"},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["tensor(5, dtype=torch.uint8)\n","num_epochs :  1000\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-c1b3a64e8ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ze4IcBtLMHS0"}}]}